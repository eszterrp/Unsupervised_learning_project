{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the ideal number of clusters with K-means and SpectralClustering\n",
    "def find_the_ideal_number_of_clusters_kmeans(X, K):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "     \n",
    "    ### Elbow method    \n",
    "    print(\"Elbow method:\")\n",
    "    # WCCS and Elbow Method: run several k-means increment k with each iteration, and record the WCCS\n",
    "    # (WCCS: Within-Cluster-Sum-of-Squares)\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "    WCCS=[]\n",
    "    for i in K:\n",
    "        kmeans = KMeans(i)\n",
    "        kmeans.fit(X)\n",
    "        wcss_iter = kmeans.inertia_\n",
    "        WCCS.append(wcss_iter)\n",
    "\n",
    "    number_clusters = K\n",
    "    plt.plot(number_clusters,WCCS, 'bx-')\n",
    "    plt.title('The Elbow title')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()\n",
    "    \n",
    "    ### Silhouette coefficient\n",
    "    print(\"Silhouette coefficient\")\n",
    "    \n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    silhouette_by_k=[]\n",
    "\n",
    "    for n_clusters in K:\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "\n",
    "        silhouette_by_k.append(silhouette_avg)\n",
    "\n",
    "    plt.plot(K, silhouette_by_k, 'bx-') \n",
    "    plt.xlabel('Values of K') \n",
    "    plt.ylabel('Silhouette') \n",
    "    plt.title('Silhouette method') \n",
    "    plt.show() \n",
    "\n",
    "    print(\"Max average silhouette score is :\", round(max(silhouette_by_k),5), \n",
    "          \" for n_clusters =\", K[silhouette_by_k.index(max(silhouette_by_k))])\n",
    "    \n",
    "    ### Gap statistics\n",
    "    # With the max value\n",
    "    print(\"Gap statistics:\")\n",
    "    from gap_statistic import OptimalK\n",
    "    from sklearn.cluster import KMeans\n",
    "    import numpy as np\n",
    "\n",
    "    optimalK = OptimalK()\n",
    "\n",
    "    n_clusters = optimalK(X, cluster_array=np.arange(2, 10))\n",
    "    print('Optimal clusters: ', n_clusters)\n",
    "\n",
    "\n",
    "    plt.plot(optimalK.gap_df.n_clusters, optimalK.gap_df.gap_value, linewidth=3)\n",
    "    plt.scatter(optimalK.gap_df[optimalK.gap_df.n_clusters == n_clusters].n_clusters,\n",
    "                optimalK.gap_df[optimalK.gap_df.n_clusters == n_clusters].gap_value, s=250, c='r')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Cluster Count')\n",
    "    plt.ylabel('Gap Value')\n",
    "    plt.title('Gap Values by Cluster Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # With the minimum value \n",
    "    gap_df=optimalK.gap_df\n",
    "    gap_df.loc[gap_df[\"diff\"]>0].head(1).n_clusters\n",
    "    print(\"with minimum value 'method' the optimal number of clusters is:\", \n",
    "     str(gap_df.loc[gap_df[\"diff\"]>0].head(1).n_clusters.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02117a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_kmeans_on_svd(n_clusters, n_components, svd_scores, df_original, plot=\"yes\"):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # fit data on KMeans\n",
    "    kmeans_svd=KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=1)\n",
    "    kmeans_svd.fit(svd_scores)\n",
    "    \n",
    "    # add SVD scores and clusters to the original df\n",
    "    df_segm_svd_kmeans=pd.concat([df_original.reset_index(drop=True),pd.DataFrame(svd_scores) ], axis=1)\n",
    "    \n",
    "    # add SVD components as new columns\n",
    "    component_columns=list()\n",
    "    for i in range(n_components):\n",
    "        component_columns.append(\"component_\"+str(i+1))\n",
    "    df_segm_svd_kmeans.columns.values[-n_components:]=component_columns\n",
    "    \n",
    "    # as last column add the kmeans labels\n",
    "    df_segm_svd_kmeans[\"segment_kmeans_svd\"]=kmeans_svd.labels_\n",
    "    df_segm_svd_kmeans[\"clusters\"]=df_segm_svd_kmeans[\"segment_kmeans_svd\"]+1\n",
    "    \n",
    "    if plot==\"yes\":\n",
    "        # Plot data\n",
    "        x_axis=df_segm_svd_kmeans.component_2\n",
    "        y_axis=df_segm_svd_kmeans.component_1\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.scatterplot(x_axis, y_axis,\n",
    "                       hue=df_segm_svd_kmeans.clusters,\n",
    "                        palette=\"Set2\")\n",
    "        plt.title(\"Clusters by SVD components\")\n",
    "        plt.legend(title='Clusters')\n",
    "        plt.show()\n",
    "        \n",
    "        return df_segm_svd_kmeans\n",
    "    else:   \n",
    "        return df_segm_svd_kmeans\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727f7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_svd(n_components, scaled_data):\n",
    "    from sklearn.decomposition import TruncatedSVD, PCA\n",
    "    \n",
    "    svd = TruncatedSVD(n_components)\n",
    "    svd.fit(scaled_data)\n",
    "    return svd.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7339905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies\n",
    "def get_dummies(df,columns):\n",
    "    import pandas as pd\n",
    "    return pd.get_dummies(data=df, columns=columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcfbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_optimal_dimensions(data):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # SVD for the scaled data\n",
    "    Ul, Dl, Vt = np.linalg.svd(data)\n",
    "    Vl = Vt.transpose()\n",
    "    # print the new coordinate vectors:\n",
    "    print(\"New coordinate vectors\")\n",
    "    plt.plot(Dl)\n",
    "    plt.show()\n",
    "\n",
    "    # explained variance\n",
    "    Zlext_more = np.matmul(Ul[:,0:10],np.diag(Dl[0:10]))\n",
    "    df_explained = pd.DataFrame(Zlext_more)\n",
    "    df_explained.var().plot(marker='o', linestyle=\"--\",\n",
    "                            title=\"Explained variance\") # This drop off provides us an indicator of how many to pick \n",
    "    plt.show()\n",
    "    \n",
    "    # Error of low dimensional representation\n",
    "    print(\"Optimal low-rank approximation\")\n",
    "    rmax = data.shape[1]+1\n",
    "    errors = np.zeros(rmax-1)\n",
    "    r = range(1,rmax)\n",
    "    n=data.shape[0]\n",
    "    p=data.shape[1]\n",
    "    for i in r:\n",
    "        Zext_temp = np.matmul(Ul[:,0:i],np.diag(Dl[0:i]))\n",
    "        Xapprox = np.matmul(Zext_temp,np.transpose(Vl[:,0:i]))\n",
    "        resid = data-Xapprox\n",
    "        residsq = np.matmul(resid.transpose(),resid)\n",
    "        errors[i-1] = residsq.trace()\n",
    "    #plt.plot(r,errors)\n",
    "    plt.plot(r,errors/(n*p)) # errros per point\n",
    "    plt.xlabel('Final low-rank dimensions')\n",
    "    plt.ylabel('Error of low dimensional representation')\n",
    "    #plt.title(\"Optimal low-rank approximation\")\n",
    "    plt.show()\n",
    "\n",
    "    # Drop in error\n",
    "    print(\"Drop in error\")\n",
    "    plt.plot(r[1:],abs(np.diff(errors/(n*p))),marker='o', linestyle=\"--\")\n",
    "    plt.xticks(np.arange(min(r[1:]),data.shape[1]+1 , 1.0))\n",
    "    plt.xlabel('Final low-rank dimensions')\n",
    "    plt.ylabel('Drop in error of low dimensional representation')\n",
    "    #plt.title(\"Drop in error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_icd9_codes(x):\n",
    "    if (x >= 1 and x<=139):\n",
    "        return 'infectious and parasitic diseases'\n",
    "    elif (x >= 140 and x<=239):\n",
    "        return 'neoplasms'\n",
    "    elif (x >= 240 and x<=279):\n",
    "        return 'endocrine, nutritional and metabolic diseases, and immunity disorders'\n",
    "    elif (x >= 280 and x<= 289):\n",
    "        return 'diseases of the blood and blood-forming organs'\n",
    "    elif (x >= 290 and x<=319):\n",
    "        return 'mental disorders'\n",
    "    elif (x >= 320 and x<=389):\n",
    "        return 'diseases of the nervous system and sense organs'\n",
    "    elif (x >= 390 and x<=459):\n",
    "        return 'diseases of the circulatory system' \n",
    "    elif (x >= 460 and x<=519):\n",
    "        return 'diseases of the respiratory system'\n",
    "    \n",
    "    elif (x >= 520 and x<=579):\n",
    "        return 'diseases of the digestive system'\n",
    "        \n",
    "    elif (x >= 580 and x<=629):\n",
    "        return 'diseases of the genitourinary system'\n",
    "        \n",
    "    elif (x >= 630 and x<=679):\n",
    "        return 'complications of pregnancy, childbirth, and the puerperium'\n",
    "        \n",
    "    elif (x >= 680 and x<=709):\n",
    "        return 'diseases of the skin and subcutaneous tissue'\n",
    "        \n",
    "    elif (x >= 710 and x<=739):\n",
    "        return 'diseases of the musculoskeletal system and connective tissue'\n",
    "        \n",
    "    elif (x >= 740 and x<=759):\n",
    "        return 'congenital anomalies'\n",
    "        \n",
    "    elif (x >= 710 and x<=779):\n",
    "        return 'certain conditions originating in the perinatal period'\n",
    "        \n",
    "    elif (x >= 780 and x<=799):\n",
    "        return 'symptoms, signs, and ill-defined conditions'\n",
    "        \n",
    "    elif (x >= 800 and x<=999):\n",
    "        return \"injury and poisoning\"\n",
    "    else:\n",
    "        return 'external causes of injury and supplemental classification'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684bff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_diagnoses_by_clusters(diagnoses_responses, cluster):\n",
    "    df=pd.DataFrame(diagnoses_responses.groupby([cluster, 'icd9_groups_conc']).size()).reset_index()\n",
    "\n",
    "    df.sort_values(by=0, ascending=False, inplace=True)\n",
    "\n",
    "    df=df.groupby(cluster).head(3).sort_values(by=cluster)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7363b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcomes_barplots(diagnoses_df, cluster_col, category_col):\n",
    "    mean = lambda x: x.mean()\n",
    "    outcomes_by=diagnoses_responses.groupby([cluster_col, \n",
    "                                                 category_col])[\"los\", \n",
    "                                                                    \"diagnosis_count\", \n",
    "                                                                    \"hospital_expire_flag\"].agg(mean).reset_index()\n",
    "\n",
    "    outcomes_by=outcomes_by.rename(columns={\"hospital_expire_flag\": \"death_rate\"})\n",
    "\n",
    "    # Visualize results by age\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.catplot(x=category_col, col=cluster_col, y=\"death_rate\",\n",
    "                     kind=\"bar\", data=outcomes_by, palette=\"Set2\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebebc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the correction factor: \n",
    "def reweight(pi,q1,r1):\n",
    "    r0 = 1-r1\n",
    "    q0 = 1-q1\n",
    "    tot = pi*(q1/r1)+(1-pi)*(q0/r0)\n",
    "    w = pi*(q1/r1)\n",
    "    w /= tot\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate_binary(X,y, model, crossval=\"Yes\"):\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import pandas as pd\n",
    "    \n",
    "    model.fit(X,y)\n",
    "    y_hat=model.predict_proba(X)\n",
    "    \n",
    "    # reweighting \n",
    "    q1 = y.sum()/len(y)\n",
    "    r1 = 0.5\n",
    "    y_hat_corr=reweight(y_hat[:,1], q1,r1)\n",
    "    \n",
    "    \n",
    "    ### Evaluate Model ###\n",
    "    y_pred_new = [1 if pi >= 0.25 else 0 for pi in y_hat_corr]\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix \\n\")\n",
    "    # insample_labels = model.predict(X)\n",
    "    cm =  confusion_matrix(y_pred=y_pred_new, y_true=y, labels=[0,1])\n",
    "    print (cm)\n",
    "    \n",
    "    # Plotting confusion matrix (custom help function)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in class_labels],\n",
    "                  columns = [i for i in class_labels])\n",
    "    sns.set(font_scale=1)\n",
    "    sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"Real label\")\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC AUC score\n",
    "    #get_auc(y_original,y_hat_corr , class_labels, column=1, plot=True) \n",
    "    fpr, tpr, _ = metrics.roc_curve(y == 1, y_hat_corr,drop_intermediate = False)\n",
    "    roc_auc = metrics.roc_auc_score(y_true=y, y_score=y_hat_corr)\n",
    "    print (\"AUC: \", roc_auc)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification report of the model: \\n\", \n",
    "      metrics.classification_report(y,y_pred_new))\n",
    "    \n",
    "    if crossval==\"Yes\":\n",
    "        # cross validation\n",
    "        print(\"Confusion matrix of in-sample cross-validation:\")\n",
    "\n",
    "        from sklearn.model_selection import cross_val_predict as cvp\n",
    "        y_hat_cv = cvp(model, X, y, cv=100)\n",
    "\n",
    "        cm2 =  confusion_matrix(y_pred=y_hat_cv, y_true=y, labels=[0,1])\n",
    "        #print(cm2)\n",
    "        df_cm2 = pd.DataFrame(cm2, index = [i for i in class_labels],\n",
    "                      columns = [i for i in class_labels])\n",
    "        sns.set(font_scale=1)\n",
    "        sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\n",
    "        plt.xlabel(\"Predicted label\")\n",
    "        plt.ylabel(\"Real label\")\n",
    "        plt.show()\n",
    "        \n",
    "    elif crossval==\"No\":\n",
    "        print(\"No cross-validation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
